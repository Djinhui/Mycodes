[2023-02-28 09:24:16] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_embeddings.word_embeddings.embedding.weight,形状为: torch.Size([21128, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_embeddings.position_embeddings.embedding.weight,形状为: torch.Size([512, 768])
[2023-02-28 09:24:26] - INFO: 模型参数max_positional_embedding > 512，采用替换处理！
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_embeddings.token_type_embeddings.embedding.weight,形状为: torch.Size([2, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_embeddings.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_embeddings.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_pooler.dense.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:24:26] - DEBUG: ## 成功赋值参数:bert_pooler.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:24:26] - INFO: ## 注意，正在使用torch框架中的MultiHeadAttention实现，如需使用本地实现的MultiHeadAttention课将
[2023-02-28 09:24:44] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.embeddings.word_embeddings.weight赋值给bert_embeddings.word_embeddings.embedding.weight,参数形状为:torch.Size([21128, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.embeddings.position_embeddings.weight赋值给bert_embeddings.position_embeddings.embedding.weight,参数形状为:torch.Size([518, 768])
[2023-02-28 09:24:51] - INFO: 模型参数max_positional_embedding > 512，采用替换处理！
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.embeddings.token_type_embeddings.weight赋值给bert_embeddings.token_type_embeddings.embedding.weight,参数形状为:torch.Size([2, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.embeddings.LayerNorm.gamma赋值给bert_embeddings.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.embeddings.LayerNorm.beta赋值给bert_embeddings.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.query.weight赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.query.bias赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.key.weight赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.key.bias赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.value.weight赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.value.bias赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.output.dense.weight赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.output.dense.bias赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.0.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.0.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.intermediate.dense.weight赋值给bert_encoder.bert_layers.0.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.intermediate.dense.bias赋值给bert_encoder.bert_layers.0.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.output.dense.weight赋值给bert_encoder.bert_layers.0.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.output.dense.bias赋值给bert_encoder.bert_layers.0.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.0.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.output.LayerNorm.beta赋值给bert_encoder.bert_layers.0.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.query.weight赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.query.bias赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.key.weight赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.key.bias赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.value.weight赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.value.bias赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.output.dense.weight赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.output.dense.bias赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.1.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.1.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.intermediate.dense.weight赋值给bert_encoder.bert_layers.1.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.intermediate.dense.bias赋值给bert_encoder.bert_layers.1.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.output.dense.weight赋值给bert_encoder.bert_layers.1.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.output.dense.bias赋值给bert_encoder.bert_layers.1.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.1.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.output.LayerNorm.beta赋值给bert_encoder.bert_layers.1.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.query.weight赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.query.bias赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.key.weight赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.key.bias赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.value.weight赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.value.bias赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.output.dense.weight赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.output.dense.bias赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.2.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.2.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.intermediate.dense.weight赋值给bert_encoder.bert_layers.2.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.intermediate.dense.bias赋值给bert_encoder.bert_layers.2.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.output.dense.weight赋值给bert_encoder.bert_layers.2.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.output.dense.bias赋值给bert_encoder.bert_layers.2.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.2.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.output.LayerNorm.beta赋值给bert_encoder.bert_layers.2.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.query.weight赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.query.bias赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.key.weight赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.key.bias赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.value.weight赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.value.bias赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.output.dense.weight赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.output.dense.bias赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.3.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.3.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.intermediate.dense.weight赋值给bert_encoder.bert_layers.3.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.intermediate.dense.bias赋值给bert_encoder.bert_layers.3.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.output.dense.weight赋值给bert_encoder.bert_layers.3.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.output.dense.bias赋值给bert_encoder.bert_layers.3.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.3.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.output.LayerNorm.beta赋值给bert_encoder.bert_layers.3.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.query.weight赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.query.bias赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.key.weight赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.key.bias赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.value.weight赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.value.bias赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.output.dense.weight赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.output.dense.bias赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.4.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.4.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.intermediate.dense.weight赋值给bert_encoder.bert_layers.4.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.intermediate.dense.bias赋值给bert_encoder.bert_layers.4.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.output.dense.weight赋值给bert_encoder.bert_layers.4.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.output.dense.bias赋值给bert_encoder.bert_layers.4.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.4.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.output.LayerNorm.beta赋值给bert_encoder.bert_layers.4.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.query.weight赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.query.bias赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.key.weight赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.key.bias赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.value.weight赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.value.bias赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.output.dense.weight赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.output.dense.bias赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.5.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.5.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.intermediate.dense.weight赋值给bert_encoder.bert_layers.5.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.intermediate.dense.bias赋值给bert_encoder.bert_layers.5.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.output.dense.weight赋值给bert_encoder.bert_layers.5.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.output.dense.bias赋值给bert_encoder.bert_layers.5.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.5.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.output.LayerNorm.beta赋值给bert_encoder.bert_layers.5.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.query.weight赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.query.bias赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.key.weight赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.key.bias赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.value.weight赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.value.bias赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.output.dense.weight赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.output.dense.bias赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.6.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.6.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.intermediate.dense.weight赋值给bert_encoder.bert_layers.6.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.intermediate.dense.bias赋值给bert_encoder.bert_layers.6.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.output.dense.weight赋值给bert_encoder.bert_layers.6.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.output.dense.bias赋值给bert_encoder.bert_layers.6.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.6.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.output.LayerNorm.beta赋值给bert_encoder.bert_layers.6.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.query.weight赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.query.bias赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.key.weight赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.key.bias赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.value.weight赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.value.bias赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.output.dense.weight赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.output.dense.bias赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.7.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.7.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.intermediate.dense.weight赋值给bert_encoder.bert_layers.7.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.intermediate.dense.bias赋值给bert_encoder.bert_layers.7.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.output.dense.weight赋值给bert_encoder.bert_layers.7.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.output.dense.bias赋值给bert_encoder.bert_layers.7.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.7.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.output.LayerNorm.beta赋值给bert_encoder.bert_layers.7.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.query.weight赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.query.bias赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.key.weight赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.key.bias赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.value.weight赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.value.bias赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.output.dense.weight赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.output.dense.bias赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.8.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.8.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.intermediate.dense.weight赋值给bert_encoder.bert_layers.8.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.intermediate.dense.bias赋值给bert_encoder.bert_layers.8.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.output.dense.weight赋值给bert_encoder.bert_layers.8.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.output.dense.bias赋值给bert_encoder.bert_layers.8.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.8.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.output.LayerNorm.beta赋值给bert_encoder.bert_layers.8.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.query.weight赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.query.bias赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.key.weight赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.key.bias赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.value.weight赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.value.bias赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.output.dense.weight赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.output.dense.bias赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.9.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.9.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.intermediate.dense.weight赋值给bert_encoder.bert_layers.9.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.intermediate.dense.bias赋值给bert_encoder.bert_layers.9.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.output.dense.weight赋值给bert_encoder.bert_layers.9.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.output.dense.bias赋值给bert_encoder.bert_layers.9.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.9.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.output.LayerNorm.beta赋值给bert_encoder.bert_layers.9.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.query.weight赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.query.bias赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.key.weight赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.key.bias赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.value.weight赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.value.bias赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.output.dense.weight赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.output.dense.bias赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.10.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.10.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.intermediate.dense.weight赋值给bert_encoder.bert_layers.10.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.intermediate.dense.bias赋值给bert_encoder.bert_layers.10.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.output.dense.weight赋值给bert_encoder.bert_layers.10.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.output.dense.bias赋值给bert_encoder.bert_layers.10.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.10.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.output.LayerNorm.beta赋值给bert_encoder.bert_layers.10.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.query.weight赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.query.bias赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.key.weight赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.key.bias赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.value.weight赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.value.bias赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.output.dense.weight赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.output.dense.bias赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.11.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.11.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.intermediate.dense.weight赋值给bert_encoder.bert_layers.11.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.intermediate.dense.bias赋值给bert_encoder.bert_layers.11.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.output.dense.weight赋值给bert_encoder.bert_layers.11.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.output.dense.bias赋值给bert_encoder.bert_layers.11.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.11.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.output.LayerNorm.beta赋值给bert_encoder.bert_layers.11.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.pooler.dense.weight赋值给bert_pooler.dense.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:24:51] - DEBUG: ## 成功将参数:bert.pooler.dense.bias赋值给bert_pooler.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:24:51] - INFO: ## 注意，正在使用本地MyTransformer中的MyMultiHeadAttention实现
[2023-02-28 09:27:19] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_embeddings.word_embeddings.embedding.weight,形状为: torch.Size([21128, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_embeddings.position_embeddings.embedding.weight,形状为: torch.Size([512, 768])
[2023-02-28 09:27:26] - INFO: 模型参数max_positional_embedding > 512，采用替换处理！
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_embeddings.token_type_embeddings.embedding.weight,形状为: torch.Size([2, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_embeddings.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_embeddings.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_pooler.dense.weight,形状为: torch.Size([768, 768])
[2023-02-28 09:27:26] - DEBUG: ## 成功赋值参数:bert_pooler.dense.bias,形状为: torch.Size([768])
[2023-02-28 09:27:26] - INFO: ## 注意，正在使用torch框架中的MultiHeadAttention实现
[2023-02-28 09:27:39] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.embeddings.word_embeddings.weight赋值给bert_embeddings.word_embeddings.embedding.weight,参数形状为:torch.Size([21128, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.embeddings.position_embeddings.weight赋值给bert_embeddings.position_embeddings.embedding.weight,参数形状为:torch.Size([518, 768])
[2023-02-28 09:27:46] - INFO: 模型参数max_positional_embedding > 512，采用替换处理！
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.embeddings.token_type_embeddings.weight赋值给bert_embeddings.token_type_embeddings.embedding.weight,参数形状为:torch.Size([2, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.embeddings.LayerNorm.gamma赋值给bert_embeddings.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.embeddings.LayerNorm.beta赋值给bert_embeddings.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.query.weight赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.query.bias赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.key.weight赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.key.bias赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.value.weight赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.value.bias赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.output.dense.weight赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.output.dense.bias赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.0.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.0.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.intermediate.dense.weight赋值给bert_encoder.bert_layers.0.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.intermediate.dense.bias赋值给bert_encoder.bert_layers.0.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.output.dense.weight赋值给bert_encoder.bert_layers.0.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.output.dense.bias赋值给bert_encoder.bert_layers.0.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.0.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.0.output.LayerNorm.beta赋值给bert_encoder.bert_layers.0.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.query.weight赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.query.bias赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.key.weight赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.key.bias赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.value.weight赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.value.bias赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.output.dense.weight赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.output.dense.bias赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.1.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.1.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.intermediate.dense.weight赋值给bert_encoder.bert_layers.1.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.intermediate.dense.bias赋值给bert_encoder.bert_layers.1.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.output.dense.weight赋值给bert_encoder.bert_layers.1.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.output.dense.bias赋值给bert_encoder.bert_layers.1.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.1.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.1.output.LayerNorm.beta赋值给bert_encoder.bert_layers.1.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.query.weight赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.query.bias赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.key.weight赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.key.bias赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.value.weight赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.value.bias赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.output.dense.weight赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.output.dense.bias赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.2.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.2.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.intermediate.dense.weight赋值给bert_encoder.bert_layers.2.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.intermediate.dense.bias赋值给bert_encoder.bert_layers.2.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.output.dense.weight赋值给bert_encoder.bert_layers.2.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.output.dense.bias赋值给bert_encoder.bert_layers.2.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.2.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.2.output.LayerNorm.beta赋值给bert_encoder.bert_layers.2.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.query.weight赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.query.bias赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.key.weight赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.key.bias赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.value.weight赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.value.bias赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.output.dense.weight赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.output.dense.bias赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.3.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.3.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.intermediate.dense.weight赋值给bert_encoder.bert_layers.3.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.intermediate.dense.bias赋值给bert_encoder.bert_layers.3.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.output.dense.weight赋值给bert_encoder.bert_layers.3.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.output.dense.bias赋值给bert_encoder.bert_layers.3.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.3.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.3.output.LayerNorm.beta赋值给bert_encoder.bert_layers.3.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.query.weight赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.query.bias赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.key.weight赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.key.bias赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.value.weight赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.value.bias赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.output.dense.weight赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.output.dense.bias赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.4.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.4.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.intermediate.dense.weight赋值给bert_encoder.bert_layers.4.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.intermediate.dense.bias赋值给bert_encoder.bert_layers.4.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.output.dense.weight赋值给bert_encoder.bert_layers.4.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.output.dense.bias赋值给bert_encoder.bert_layers.4.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.4.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.4.output.LayerNorm.beta赋值给bert_encoder.bert_layers.4.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.query.weight赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.query.bias赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.key.weight赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.key.bias赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.value.weight赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.value.bias赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.output.dense.weight赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.output.dense.bias赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.5.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.5.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.intermediate.dense.weight赋值给bert_encoder.bert_layers.5.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.intermediate.dense.bias赋值给bert_encoder.bert_layers.5.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.output.dense.weight赋值给bert_encoder.bert_layers.5.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.output.dense.bias赋值给bert_encoder.bert_layers.5.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.5.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.5.output.LayerNorm.beta赋值给bert_encoder.bert_layers.5.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.query.weight赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.query.bias赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.key.weight赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.key.bias赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.value.weight赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.value.bias赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.output.dense.weight赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.output.dense.bias赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.6.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.6.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.intermediate.dense.weight赋值给bert_encoder.bert_layers.6.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.intermediate.dense.bias赋值给bert_encoder.bert_layers.6.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.output.dense.weight赋值给bert_encoder.bert_layers.6.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.output.dense.bias赋值给bert_encoder.bert_layers.6.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.6.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.6.output.LayerNorm.beta赋值给bert_encoder.bert_layers.6.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.query.weight赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.query.bias赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.key.weight赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.key.bias赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.value.weight赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.value.bias赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.output.dense.weight赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.output.dense.bias赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.7.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.7.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.intermediate.dense.weight赋值给bert_encoder.bert_layers.7.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.intermediate.dense.bias赋值给bert_encoder.bert_layers.7.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.output.dense.weight赋值给bert_encoder.bert_layers.7.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.output.dense.bias赋值给bert_encoder.bert_layers.7.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.7.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.7.output.LayerNorm.beta赋值给bert_encoder.bert_layers.7.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.query.weight赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.query.bias赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.key.weight赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.key.bias赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.value.weight赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.value.bias赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.output.dense.weight赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.output.dense.bias赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.8.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.8.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.intermediate.dense.weight赋值给bert_encoder.bert_layers.8.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.intermediate.dense.bias赋值给bert_encoder.bert_layers.8.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.output.dense.weight赋值给bert_encoder.bert_layers.8.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.output.dense.bias赋值给bert_encoder.bert_layers.8.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.8.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.8.output.LayerNorm.beta赋值给bert_encoder.bert_layers.8.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.query.weight赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.query.bias赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.key.weight赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.key.bias赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.value.weight赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.value.bias赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.output.dense.weight赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.output.dense.bias赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.9.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.9.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.intermediate.dense.weight赋值给bert_encoder.bert_layers.9.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.intermediate.dense.bias赋值给bert_encoder.bert_layers.9.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.output.dense.weight赋值给bert_encoder.bert_layers.9.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.output.dense.bias赋值给bert_encoder.bert_layers.9.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.9.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.9.output.LayerNorm.beta赋值给bert_encoder.bert_layers.9.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.query.weight赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.query.bias赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.key.weight赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.key.bias赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.value.weight赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.value.bias赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.output.dense.weight赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.output.dense.bias赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.10.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.10.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.intermediate.dense.weight赋值给bert_encoder.bert_layers.10.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.intermediate.dense.bias赋值给bert_encoder.bert_layers.10.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.output.dense.weight赋值给bert_encoder.bert_layers.10.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.output.dense.bias赋值给bert_encoder.bert_layers.10.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.10.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.10.output.LayerNorm.beta赋值给bert_encoder.bert_layers.10.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.query.weight赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.query.bias赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.key.weight赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.key.bias赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.value.weight赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.value.bias赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.output.dense.weight赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.output.dense.bias赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.11.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.11.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.intermediate.dense.weight赋值给bert_encoder.bert_layers.11.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.intermediate.dense.bias赋值给bert_encoder.bert_layers.11.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.output.dense.weight赋值给bert_encoder.bert_layers.11.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.output.dense.bias赋值给bert_encoder.bert_layers.11.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.11.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.encoder.layer.11.output.LayerNorm.beta赋值给bert_encoder.bert_layers.11.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.pooler.dense.weight赋值给bert_pooler.dense.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 09:27:46] - DEBUG: ## 成功将参数:bert.pooler.dense.bias赋值给bert_pooler.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 09:27:46] - INFO: ## 注意，正在使用本地MyTransformer中的MyMultiHeadAttention实现，如需使用torch框架中的MultiHeadAttention模块可通过config.__dict__['use_torch_multi_head'] = True实现
[2023-02-28 16:09:58] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:10:11] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:10:43] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.embeddings.word_embeddings.weight赋值给bert_embeddings.word_embeddings.embedding.weight,参数形状为:torch.Size([21128, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.embeddings.position_embeddings.weight赋值给bert_embeddings.position_embeddings.embedding.weight,参数形状为:torch.Size([518, 768])
[2023-02-28 16:10:51] - INFO: 模型参数max_positional_embedding > 512，采用替换处理！
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.embeddings.token_type_embeddings.weight赋值给bert_embeddings.token_type_embeddings.embedding.weight,参数形状为:torch.Size([2, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.embeddings.LayerNorm.gamma赋值给bert_embeddings.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.embeddings.LayerNorm.beta赋值给bert_embeddings.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.query.weight赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.query.bias赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.key.weight赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.key.bias赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.value.weight赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.self.value.bias赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.output.dense.weight赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.output.dense.bias赋值给bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.0.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.0.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.intermediate.dense.weight赋值给bert_encoder.bert_layers.0.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.intermediate.dense.bias赋值给bert_encoder.bert_layers.0.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.output.dense.weight赋值给bert_encoder.bert_layers.0.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.output.dense.bias赋值给bert_encoder.bert_layers.0.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.0.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.0.output.LayerNorm.beta赋值给bert_encoder.bert_layers.0.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.query.weight赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.query.bias赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.key.weight赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.key.bias赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.value.weight赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.self.value.bias赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.output.dense.weight赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.output.dense.bias赋值给bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.1.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.1.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.intermediate.dense.weight赋值给bert_encoder.bert_layers.1.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.intermediate.dense.bias赋值给bert_encoder.bert_layers.1.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.output.dense.weight赋值给bert_encoder.bert_layers.1.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.output.dense.bias赋值给bert_encoder.bert_layers.1.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.1.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.1.output.LayerNorm.beta赋值给bert_encoder.bert_layers.1.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.query.weight赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.query.bias赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.key.weight赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.key.bias赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.value.weight赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.self.value.bias赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.output.dense.weight赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.output.dense.bias赋值给bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.2.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.2.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.intermediate.dense.weight赋值给bert_encoder.bert_layers.2.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.intermediate.dense.bias赋值给bert_encoder.bert_layers.2.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.output.dense.weight赋值给bert_encoder.bert_layers.2.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.output.dense.bias赋值给bert_encoder.bert_layers.2.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.2.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.2.output.LayerNorm.beta赋值给bert_encoder.bert_layers.2.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.query.weight赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.query.bias赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.key.weight赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.key.bias赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.value.weight赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.self.value.bias赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.output.dense.weight赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.output.dense.bias赋值给bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.3.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.3.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.intermediate.dense.weight赋值给bert_encoder.bert_layers.3.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.intermediate.dense.bias赋值给bert_encoder.bert_layers.3.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.output.dense.weight赋值给bert_encoder.bert_layers.3.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.output.dense.bias赋值给bert_encoder.bert_layers.3.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.3.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.3.output.LayerNorm.beta赋值给bert_encoder.bert_layers.3.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.query.weight赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.query.bias赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.key.weight赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.key.bias赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.value.weight赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.self.value.bias赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.output.dense.weight赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.output.dense.bias赋值给bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.4.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.4.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.intermediate.dense.weight赋值给bert_encoder.bert_layers.4.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.intermediate.dense.bias赋值给bert_encoder.bert_layers.4.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.output.dense.weight赋值给bert_encoder.bert_layers.4.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.output.dense.bias赋值给bert_encoder.bert_layers.4.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.4.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.4.output.LayerNorm.beta赋值给bert_encoder.bert_layers.4.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.query.weight赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.query.bias赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.key.weight赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.key.bias赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.value.weight赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.self.value.bias赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.output.dense.weight赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.output.dense.bias赋值给bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.5.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.5.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.intermediate.dense.weight赋值给bert_encoder.bert_layers.5.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.intermediate.dense.bias赋值给bert_encoder.bert_layers.5.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.output.dense.weight赋值给bert_encoder.bert_layers.5.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.output.dense.bias赋值给bert_encoder.bert_layers.5.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.5.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.5.output.LayerNorm.beta赋值给bert_encoder.bert_layers.5.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.query.weight赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.query.bias赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.key.weight赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.key.bias赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.value.weight赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.self.value.bias赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.output.dense.weight赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.output.dense.bias赋值给bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.6.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.6.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.intermediate.dense.weight赋值给bert_encoder.bert_layers.6.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.intermediate.dense.bias赋值给bert_encoder.bert_layers.6.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.output.dense.weight赋值给bert_encoder.bert_layers.6.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.output.dense.bias赋值给bert_encoder.bert_layers.6.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.6.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.6.output.LayerNorm.beta赋值给bert_encoder.bert_layers.6.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.query.weight赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.query.bias赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.key.weight赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.key.bias赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.value.weight赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.self.value.bias赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.output.dense.weight赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.output.dense.bias赋值给bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.7.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.7.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.intermediate.dense.weight赋值给bert_encoder.bert_layers.7.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.intermediate.dense.bias赋值给bert_encoder.bert_layers.7.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.output.dense.weight赋值给bert_encoder.bert_layers.7.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.output.dense.bias赋值给bert_encoder.bert_layers.7.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.7.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.7.output.LayerNorm.beta赋值给bert_encoder.bert_layers.7.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.query.weight赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.query.bias赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.key.weight赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.key.bias赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.value.weight赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.self.value.bias赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.output.dense.weight赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.output.dense.bias赋值给bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.8.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.8.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.intermediate.dense.weight赋值给bert_encoder.bert_layers.8.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.intermediate.dense.bias赋值给bert_encoder.bert_layers.8.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.output.dense.weight赋值给bert_encoder.bert_layers.8.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.output.dense.bias赋值给bert_encoder.bert_layers.8.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.8.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.8.output.LayerNorm.beta赋值给bert_encoder.bert_layers.8.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.query.weight赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.query.bias赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.key.weight赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.key.bias赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.value.weight赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.self.value.bias赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.output.dense.weight赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.output.dense.bias赋值给bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.9.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.9.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.intermediate.dense.weight赋值给bert_encoder.bert_layers.9.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.intermediate.dense.bias赋值给bert_encoder.bert_layers.9.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.output.dense.weight赋值给bert_encoder.bert_layers.9.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.output.dense.bias赋值给bert_encoder.bert_layers.9.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.9.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.9.output.LayerNorm.beta赋值给bert_encoder.bert_layers.9.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.query.weight赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.query.bias赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.key.weight赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.key.bias赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.value.weight赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.self.value.bias赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.output.dense.weight赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.output.dense.bias赋值给bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.10.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.10.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.intermediate.dense.weight赋值给bert_encoder.bert_layers.10.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.intermediate.dense.bias赋值给bert_encoder.bert_layers.10.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.output.dense.weight赋值给bert_encoder.bert_layers.10.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.output.dense.bias赋值给bert_encoder.bert_layers.10.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.10.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.10.output.LayerNorm.beta赋值给bert_encoder.bert_layers.10.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.query.weight赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.q_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.query.bias赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.q_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.key.weight赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.k_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.key.bias赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.k_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.value.weight赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.v_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.self.value.bias赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.v_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.output.dense.weight赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.out_proj.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.output.dense.bias赋值给bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.out_proj.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.11.bert_attention.output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.attention.output.LayerNorm.beta赋值给bert_encoder.bert_layers.11.bert_attention.output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.intermediate.dense.weight赋值给bert_encoder.bert_layers.11.bert_intermediate.dense.weight,参数形状为:torch.Size([3072, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.intermediate.dense.bias赋值给bert_encoder.bert_layers.11.bert_intermediate.dense.bias,参数形状为:torch.Size([3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.output.dense.weight赋值给bert_encoder.bert_layers.11.bert_output.dense.weight,参数形状为:torch.Size([768, 3072])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.output.dense.bias赋值给bert_encoder.bert_layers.11.bert_output.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.output.LayerNorm.gamma赋值给bert_encoder.bert_layers.11.bert_output.LayerNorm.weight,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.encoder.layer.11.output.LayerNorm.beta赋值给bert_encoder.bert_layers.11.bert_output.LayerNorm.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.pooler.dense.weight赋值给bert_pooler.dense.weight,参数形状为:torch.Size([768, 768])
[2023-02-28 16:10:51] - DEBUG: ## 成功将参数:bert.pooler.dense.bias赋值给bert_pooler.dense.bias,参数形状为:torch.Size([768])
[2023-02-28 16:10:51] - INFO: ## 注意，正在使用本地MyTransformer中的MyMultiHeadAttention实现，如需使用torch框架中的MultiHeadAttention模块可通过config.__dict__['use_torch_multi_head'] = True实现
[2023-02-28 16:11:12] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_embeddings.word_embeddings.embedding.weight,形状为: torch.Size([21128, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_embeddings.position_embeddings.embedding.weight,形状为: torch.Size([512, 768])
[2023-02-28 16:11:19] - INFO: 模型参数max_positional_embedding > 512，采用替换处理！
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_embeddings.token_type_embeddings.embedding.weight,形状为: torch.Size([2, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_embeddings.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_embeddings.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.0.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.1.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.2.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.3.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.4.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.5.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.6.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.7.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.8.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.9.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.10.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.in_proj_weight,形状为: torch.Size([2304, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.in_proj_bias,形状为: torch.Size([2304])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.out_proj.weight,形状为: torch.Size([768, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.self.multi_head_attention.out_proj.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_attention.output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_intermediate.dense.weight,形状为: torch.Size([3072, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_intermediate.dense.bias,形状为: torch.Size([3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_output.dense.weight,形状为: torch.Size([768, 3072])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_output.dense.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_output.LayerNorm.weight,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_encoder.bert_layers.11.bert_output.LayerNorm.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_pooler.dense.weight,形状为: torch.Size([768, 768])
[2023-02-28 16:11:19] - DEBUG: ## 成功赋值参数:bert_pooler.dense.bias,形状为: torch.Size([768])
[2023-02-28 16:11:19] - INFO: ## 注意，正在使用torch框架中的MultiHeadAttention实现
[2023-02-28 16:29:59] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:31:25] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:32:08] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:33:37] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:35:12] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:35:19] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:35:29] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:36:06] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:36:39] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:37:26] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:37:35] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:38:11] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:39:30] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:41:00] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:41:34] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:41:49] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:44:33] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:44:41] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:47:14] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:48:09] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:48:38] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:48:47] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:49:02] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:49:19] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:50:46] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:50:57] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:53:01] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 16:53:28] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:16:04] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:16:17] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:16:59] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:17:16] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:21:09] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:22:17] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:22:55] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:23:26] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:24:06] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:24:26] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:24:56] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:26:34] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:27:13] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:27:30] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
[2023-02-28 17:27:52] - INFO: 成功导入BERT配置文件 ../bert_base_chinese/config.json
